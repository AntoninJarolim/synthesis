// maze example (POMDP)
// slightly extends that presented in
// Littman, Cassandra and Kaelbling
// Learning policies for partially observable environments: Scaling up
// Technical Report CS, Brown University
// Encoding in PRISM by gxn 29/01/16
// Adapted as a family with memory by Sebastian Junges



// state space (value of variable "s")

//  0  1  2  3  4
//  5     6     7
//  8     9    10
// 11     12   13

// 12 is the target

dtmc

const int CMAX;
const double THRESHOLD;

const int M_0_1;
const int M_0_2;
const int M_0_3;
const int M_0_4;
const int M_0_5;
const int M_0_6;
const int M_1_1;
const int M_1_2;
const int M_1_3;
const int M_1_4;
const int M_1_5;
const int M_1_6;
const int P_0_1;
const int P_0_2;
const int P_0_3;
const int P_0_4;
const int P_0_5;
const int P_0_6;
const int P_1_1;
const int P_1_2;
const int P_1_3;
const int P_1_4;
const int P_1_5;
const int P_1_6;

// walls detector
formula wn = s>=0 & s<=4;
formula we = s=0 | (s>=5 & s<=13);
formula ws = (s>=11 & s<=13) | s=1 | s=3;
formula ww = s=4 | (s>=5 & s<=13);

// o=0 - observation in initial state
// o=1 - west and north walls (s0)
// o=2 - north and south walls (s1 and s3)
// o=3 - north wall (s2)
// o=4 - east and north wall (s4)
// o=5 - east and west walls (s5, s6, s7, s8, s9 and s10)
// o=6 - east, west and south walls (s11 and s12)

formula o1 = wn & !ws & !we & ww;
formula o2 = wn & ws & !we & !ww;
formula o3 = wn & !ws & !we & !ww;
formula o4 = wn & !ws & we & !ww;
formula o5 = !wn & !ws & we & ww;
formula o6 = !wn & ws & we & ww;

module actuator
    v : [0..4] init 0;

    [steer_north] v = 0 -> 0.8: (v'=1) + 0.08: (v'=4) + 0.08: (v'=2) + 0.04: (v'=3);
    [steer_east] v = 0 -> 0.8: (v'=2) + 0.08: (v'=1) + 0.08: (v'=3) + 0.04: (v'=4);
    [steer_south] v = 0 -> 0.8: (v'=3) + 0.08: (v'=4) + 0.08: (v'=2) + 0.04: (v'=1);
    [steer_west] v = 0 -> 0.8: (v'=4) + 0.08: (v'=4) + 0.08: (v'=2) + 0.04: (v'=2);

    [north] s != 12 & v = 1 -> (v'=0);
    [east] s != 12 & v = 2 -> (v'=0);
    [south] s != 12 & v = 3 -> (v'=0);
    [west] s != 12 & v = 4 -> (v'=0);
    [done] v != 0 -> (v'=0);

endmodule

module strategy
	pick : [0..4] init 0;
	mem : [0..1] init 0;
	[] v = 0 & pick = 0 & mem = 0 & o1 -> (mem'=M_0_1) & (pick'=P_0_1);
	[] v = 0 & pick = 0 & mem = 0 & o2 -> (mem'=M_0_2) & (pick'=P_0_2);
	[] v = 0 &  pick = 0 & mem = 0 & o3 -> (mem'=M_0_3) & (pick'=P_0_3);
	[] v = 0 & pick = 0 & mem = 0 & o4 -> (mem'=M_0_4) & (pick'=P_0_4);
	[] v = 0 & pick = 0 & mem = 0 & o5 -> (mem'=M_0_5) & (pick'=P_0_5);
	[] v = 0 & pick = 0 & mem = 0 & o6 -> (mem'=M_0_6) & (pick'=P_0_6);
	[] v = 0 & pick = 0 & mem = 1 & o1 -> (mem'=M_1_1) & (pick'=P_1_1);
	[] v = 0 & pick = 0 & mem = 1 & o2 -> (mem'=M_1_2) & (pick'=P_1_2);
	[] v = 0 & pick = 0 & mem = 1 & o3 -> (mem'=M_1_3) & (pick'=P_1_3);
	[] v = 0 & pick = 0 & mem = 1 & o4 -> (mem'=M_1_4) & (pick'=P_1_4);
	[] v = 0 & pick = 0 & mem = 1 & o5 -> (mem'=M_1_5) & (pick'=P_1_5);
	[] v = 0 & pick = 0 & mem = 1 & o6 -> (mem'=M_1_6) & (pick'=P_1_6);
	[steer_north] pick=1 -> (pick'=0);
	[steer_east] pick=2 -> (pick'=0);
	[steer_south] pick=3 -> (pick'=0);
	[steer_west] pick=4 -> (pick'=0);
endmodule



module maze

	s : [-1..13];
	

	// initialisation
	[] s=-1 -> 1/13 : (s'=0)
			 + 1/13 : (s'=1)
			 + 1/13 : (s'=2)
			 + 1/13 : (s'=3)
			 + 1/13 : (s'=4)
			 + 1/13 : (s'=5)
			 + 1/13 : (s'=6)
			 + 1/13 : (s'=7)
			 + 1/13 : (s'=8)
			 + 1/13 : (s'=9)
			 + 1/13 : (s'=10)
			 + 1/13 : (s'=11)
			 + 1/13 : (s'=13);

	// moving around the maze

	[north] wn -> true;
	[north] s=5 -> (s'=0);
	[north] s=6 -> (s'=2);
	[north] s=7 -> (s'=4);
	[north] (s>=8 & s<= 11) | s=13 -> (s'=s-3);
	
	[east] we -> true;
	[east] s>=0 & s<=3 -> (s'=s+1);

	[south] ws -> true;
	[south] s=0 -> (s'=5);
	[south] s=2 -> (s'=6);
	[south] s=4 -> (s'=7);
	[south] s>=5 & s<=10 -> (s'=s+3);

	[west] ww -> true;
	[west] s>=1 & s<=4 -> (s'=s-1);

	// loop when we reach the target
	[done] s=12 -> true;

endmodule

module counter
    c : [0..CMAX] init 0;
    [east] true -> (c'=min(CMAX, c+1));
    [west] true -> (c'=min(CMAX, c+1));
    [north] true -> (c'=min(CMAX, c+1));
    [south] true -> (c'=min(CMAX, c+1));
endmodule

// reward structure (number of steps to reach the target)
rewards "steps"
	[east] true : 1;
	[west] true : 1;
	[north] true : 1;
	[south] true : 1;
endrewards

// target observation
label "goal" = s=12;
// label "traps" = s=11 | s=13;
